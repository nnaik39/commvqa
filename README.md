# CommVQA: Situating Visual Question Answering in Communicative Contexts

This is the official Github repository for our paper CommVQA: Situating Visual Question Answering in Communicative Contexts (Arxiv, 2024). We provide the code and data necessary to replicate our results.

## Downloading the CommVQA Dataset
CommVQA is a dataset introduced in our paper and contains Wikipedia images with their respective captions, alt descriptions and the broader context the images are situated in.

For details on downloading CommVQA, navigate to Concadia_dataset/.

## Reproducing Section 4: Model Experiments
Please navigate to models/ for more details.

## Citation
If you find this repo or the paper useful in your research, please feel free to cite our paper:
```
@inproceedings{Naik-etal:2024,
    author = {Naik, Nandita and Potts, Christopher and Kreiss, Elisa},
    booktitle={arXiv},
    year = {2024},
    title = {{CommVQA}: Situating {Visual Question Answering} in {Communicative Contexts}
```
