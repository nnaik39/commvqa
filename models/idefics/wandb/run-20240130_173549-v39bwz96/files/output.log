

Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.18s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Using sep_token, but it is not set yet.
Using cls_token, but it is not set yet.
Using mask_token, but it is not set yet.
  0%|                                                  | 0/1215 [00:08<?, ?it/s]
Traceback (most recent call last):
  File "/juice2/scr2/nanditan/commvqa/idefics/eval_idefics.py", line 131, in <module>
    metrics_dict = evaluate_metrics(refs, generated_answer, ['../' + image_path], 1)
  File "/juice2/scr2/nanditan/commvqa/idefics/eval_idefics.py", line 60, in evaluate_metrics
    metrics_dict = get_all_metrics([refs], [cands])
  File "/juice2/scr2/nanditan/commvqa/idefics/clipscore_helper.py", line 40, in get_all_metrics
    overall, per_cap = pycoco_eval(scorer, refs, cands)
  File "/juice2/scr2/nanditan/commvqa/idefics/clipscore_helper.py", line 77, in pycoco_eval
    average_score, scores = scorer.compute_score(refs, cands)
  File "/nlp/scr/nanditan/miniconda3/lib/python3.9/site-packages/pycocoevalcap/bleu/bleu.py", line 23, in compute_score
    assert(gts.keys() == res.keys())
AssertionError