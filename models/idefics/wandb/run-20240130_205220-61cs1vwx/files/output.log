


Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.98s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Using sep_token, but it is not set yet.
Using cls_token, but it is not set yet.
Using mask_token, but it is not set yet.
  0%|                                                  | 0/1215 [00:00<?, ?it/s]
Refs  [[['there are not any other objects.', 'small fish', 'there are no other creatures or objects around the stingray']]]
  0%|                                                  | 0/1215 [00:00<?, ?it/s]/nlp/scr/nanditan/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
100%|█████████████████████████████████████████████| 1/1 [00:03<00:00,  3.00s/it]
/juice2/scr2/nanditan/commvqa/idefics/clipscore_helper.py:167: UserWarning: due to a numerical instability, new numpy normalization is slightly different than paper results. to exactly replicate paper results, please use numpy version less than 1.21, e.g., 1.20.3.
  warnings.warn(
/juice2/scr2/nanditan/commvqa/idefics/clipscore_helper.py:196: UserWarning: due to a numerical instability, new numpy normalization is slightly different than paper results. to exactly replicate paper results, please use numpy version less than 1.21, e.g., 1.20.3.
  warnings.warn(
1it [00:00, 3938.31it/s]
  0%|                                                  | 0/1215 [00:25<?, ?it/s]
Traceback (most recent call last):
  File "/juice2/scr2/nanditan/commvqa/idefics/eval_idefics.py", line 193, in <module>
    metrics_per_context[context] = evaluate_metrics(
  File "/juice2/scr2/nanditan/commvqa/idefics/eval_idefics.py", line 35, in evaluate_metrics
    metrics_dict = get_all_metrics([refs_sample], [cands_sample])
  File "/juice2/scr2/nanditan/commvqa/idefics/clipscore_helper.py", line 40, in get_all_metrics
    overall, per_cap = pycoco_eval(scorer, refs, cands)
  File "/juice2/scr2/nanditan/commvqa/idefics/clipscore_helper.py", line 76, in pycoco_eval
    refs, cands = tokenize(refs, cands)
  File "/juice2/scr2/nanditan/commvqa/idefics/clipscore_helper.py", line 64, in tokenize
    refs = tokenizer.tokenize(refs)
  File "/nlp/scr/nanditan/miniconda3/lib/python3.9/site-packages/pycocoevalcap/tokenizer/ptbtokenizer.py", line 37, in tokenize
    sentences = '\n'.join([c['caption'].replace('\n', ' ') for k, v in captions_for_image.items() for c in v])
  File "/nlp/scr/nanditan/miniconda3/lib/python3.9/site-packages/pycocoevalcap/tokenizer/ptbtokenizer.py", line 37, in <listcomp>
    sentences = '\n'.join([c['caption'].replace('\n', ' ') for k, v in captions_for_image.items() for c in v])
AttributeError: 'list' object has no attribute 'replace'
Indices  [0]